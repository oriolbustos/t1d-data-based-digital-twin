{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ea03d97",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#1e1e1e; padding:25px; border-radius:10px; display:table; width:100%;\">\n",
    "\n",
    "  <!-- Left column: text -->\n",
    "  <div style=\"display:table-cell; vertical-align:top; width:70%; padding-right:10px;\">\n",
    "    <h1 style=\"color:#4FC3F7; margin-bottom:10px;\">Hands-On Part B: Personalization Methods</h1>\n",
    "\n",
    "  <p style=\"font-size:18px; font-style:italic; color:#cccccc;\">\n",
    "    Workshop on T1D Simulator and Digital Twins for Personalized Care\n",
    "  </p>\n",
    "\n",
    "  <p style=\"font-size:15px; line-height:1.6; color:#dddddd;\">\n",
    "  Prepare the data for the fine-tuning loop, train the GAN and simulate the obtained model. \n",
    "  </p>\n",
    "  </div>\n",
    "\n",
    "  <!-- Right column: logo -->\n",
    "  <div style=\"display:table-cell; vertical-align:middle; text-align:left; width:30%; padding-right:50px;\">\n",
    "    <img src=\"https://micelab.udg.edu/wp-content/uploads/2022/08/MICElab-letras_png-300x119.png\" alt=\"MiceLab Logo\" style=\"height:80px; border-radius:8px;\">\n",
    "  </div>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df3147c",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#4FC3F7; border-bottom:2px solid #4FC3F7; padding-bottom:4px;\">\n",
    "0. Imports &amp; Set-Up\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6827b06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "sys.path.append(os.path.abspath(\"../scripts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752529e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from datetime import datetime\n",
    "from types import SimpleNamespace\n",
    "import pytz\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scripts.data_classes import TrainingData\n",
    "from scripts.gan import GANModel\n",
    "from scripts.simulate import SimulatorVAEGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b00b7ad",
   "metadata": {},
   "source": [
    "Check GPU availability for TensorFlow, not essential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211efa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5bfa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, contextlib, io\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'   # still useful for later logs\n",
    "os.environ['ABSL_LOG_LEVEL']      = '3'\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def mute_tensorflow_startup():\n",
    "    \"\"\"Silence C++ factory/placer warnings emitted during the first TF import.\"\"\"\n",
    "    stderr_fileno = sys.stderr.fileno()\n",
    "    with open(os.devnull, 'w') as devnull:\n",
    "        saved_stderr = os.dup(stderr_fileno)\n",
    "        os.dup2(devnull.fileno(), stderr_fileno)   # redirect to /dev/null\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            os.dup2(saved_stderr, stderr_fileno)   # restore stderr\n",
    "            os.close(saved_stderr)\n",
    "\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior() # essential for indexing tensors, code crashes without this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a45fd20",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#4FC3F7; border-bottom:2px solid #4FC3F7; padding-bottom:4px;\">\n",
    "1. Load Model & Data\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c41e56",
   "metadata": {},
   "source": [
    "Setup path and model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcfe1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"../misc/\"\n",
    "model_name = \"pretrained-model.h5\"\n",
    "model_name = \"vae_decoder_epoch_010.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7049c173",
   "metadata": {},
   "source": [
    "Load the .h5 using the `load_model` method from keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270297d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = Path(path_to_model, model_name)\n",
    "pretrained_vae_model = tf.keras.models.load_model(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d0ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_df = Path(\"../misc/data_processed.csv\")\n",
    "\n",
    "df = pd.read_csv(path_df)\n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea39e81",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#4FC3F7; border-bottom:2px solid #4FC3F7; padding-bottom:4px;\">\n",
    "2. Settings & Preprocessing\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f9f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings = SimpleNamespace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9840be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing settings\n",
    "settings.random_state = 0\n",
    "settings.scaler_range = (0, 1)\n",
    "settings.glucose_dim = int(90/5) # prediction horizon 90 min, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e541fcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training settings\n",
    "settings.in_data_shape = (1, 1)\n",
    "settings.weight_clip = 1\n",
    "\n",
    "settings.learning_rate_discriminator = 1e-05\n",
    "settings.learning_rate_generator = 1e-05\n",
    "settings.ratio_generator_losses = [1, 1]\n",
    "\n",
    "settings.n_epochs_gan = 20\n",
    "settings.batch_size_gan = 32\n",
    "\n",
    "settings.y_real_label = 1\n",
    "settings.y_fake_label = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc729f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation settings\n",
    "settings.simulation_length_in_days = 2\n",
    "settings.padding_steps = 12 # 12*5min = 1h padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9329c0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't modify these unless you know what you're doing\n",
    "settings.gan_inputs = ['BG', 'PI', 'RA']\n",
    "settings.scalers_path = '../misc/'\n",
    "settings.out_data_shape = (1, settings.glucose_dim)\n",
    "settings.latent_dimensions = settings.glucose_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5e5f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_minmax_scaling(data: np.ndarray, scaler_range: tuple) -> tuple[np.ndarray, float, float]:\n",
    "    \"\"\"\n",
    "    Perform manual min-max scaling on the data.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): Data to scale.\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, float, float]: Scaled data, minimum value, and maximum value.\n",
    "    \"\"\"\n",
    "    lower_bound = scaler_range[0]\n",
    "    upper_bound = scaler_range[1]\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    scaled_data = lower_bound + (upper_bound - lower_bound) * (data - min_val) / (max_val - min_val)\n",
    "\n",
    "    return scaled_data, min_val, max_val\n",
    "\n",
    "def individual_min_max_scaling(\n",
    "    df: pd.DataFrame, base_output_dir: Path, scaler_range: tuple, gan_inputs: list\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform individual min-max scaling on the dataframe columns.\n",
    "    Scale all three columns the same way and save only the scalers for 'BG'.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe to scale.\n",
    "        base_output_dir (Path): Directory to save the scalers.\n",
    "    Returns:\n",
    "        pd.DataFrame: Scaled dataframe.\n",
    "    \"\"\"\n",
    "    scalers: dict[str, list[float]] = {'BG_min': [], 'BG_max': []}\n",
    "    scaled_dfs: list[pd.DataFrame] = []\n",
    "\n",
    "    for column in gan_inputs:\n",
    "        if column not in ['BG', 'IG']:\n",
    "            df[f'sc{column}'], _, _ = manual_minmax_scaling(df[column], scaler_range)\n",
    "\n",
    "    df['scBG'], min_val, max_val = (manual_minmax_scaling(df['BG'], scaler_range))\n",
    "\n",
    "    scalers['BG_min'].append(min_val)\n",
    "    scalers['BG_max'].append(max_val)\n",
    "\n",
    "    scaled_dfs.append(df)\n",
    "\n",
    "    scaled_df = pd.concat(scaled_dfs, ignore_index=True)\n",
    "    scaled_df = scaled_df.sort_values(by=['ID', 'iteration']).reset_index(drop=True)\n",
    "\n",
    "    save_scalers(pd.DataFrame(scalers), base_output_dir)\n",
    "\n",
    "    return scaled_df\n",
    "\n",
    "def save_scalers(scalers_df: pd.DataFrame, base_output_dir: Path) -> None:\n",
    "    \"\"\"\n",
    "    Save the scalers to a file.\n",
    "\n",
    "    Args:\n",
    "        scalers (Dict[str, List[float]]): Dictionary containing the scalers.\n",
    "        base_output_dir (Path): Directory to save the scalers.\n",
    "    \"\"\"\n",
    "    scalers_file: Path = Path(base_output_dir, 'bg_scalers.joblib')\n",
    "    joblib.dump(scalers_df, scalers_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50a2c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = df.copy(deep=True)\n",
    "\n",
    "df_scaled['iteration'] = df_scaled.groupby('ID').cumcount()\n",
    "df_scaled = individual_min_max_scaling(df_scaled, Path(settings.scalers_path), settings.scaler_range, settings.gan_inputs)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e3c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_data(df) -> None:\n",
    "    \"\"\"\n",
    "    Pack the data into vectors for each feature (BG).\n",
    "\n",
    "    This method creates packed vectors for blood glucose (BG)\n",
    "    by sliding a window over the time series data. The packed data is then\n",
    "    stored in new columns in the DataFrame.\n",
    "    \"\"\"\n",
    "    df = df.fillna(0)  # Fill NaN values with 0\n",
    "\n",
    "    # Pack blood glucose data\n",
    "    packed_bg_vectors: np.ndarray = np.array(\n",
    "        [\n",
    "            df.iloc[i : i + 18]['scBG'].values\n",
    "            for i in tqdm(range(len(df) - (18 - 1)), desc='Packing BG')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    df = df.iloc[: len(packed_bg_vectors)]\n",
    "    df['scBG_packed'] = list(packed_bg_vectors)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d3519f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_packed = pack_data(df_scaled)\n",
    "display(df_packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca30c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_inputs = ['BG', 'scBG_packed', 'PI', 'RA', 'scPI', 'scRA']\n",
    "data_dict = {column: np.array(df_packed[column].tolist(), dtype=np.float32).reshape(df_packed.shape[0], 1, -1) for column in dict_inputs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fad98be",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#4FC3F7; border-bottom:2px solid #4FC3F7; padding-bottom:4px;\">\n",
    "3. Training\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3f421a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(df, dict_inputs) -> TrainingData:\n",
    "    train_data_dict = {}\n",
    "    for input_name in dict_inputs:\n",
    "        if input_name == 'scBG_packed':\n",
    "            train_data_dict['scBG'] = df[f'{input_name}']\n",
    "        elif input_name in ['BG', 'PI', 'RA']:\n",
    "            pass\n",
    "        else:\n",
    "            train_data_dict[f'{input_name}'] = df[f'{input_name}']\n",
    "\n",
    "    train_data = TrainingData(**train_data_dict)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = load_training_data(data_dict, dict_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec1ddec",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GANModel(settings, pretrained_vae_model)\n",
    "\n",
    "timestamp = datetime.now(pytz.timezone('Europe/Madrid')).strftime(\"%Y%m%d_%H%M%S\")\n",
    "gan.gan_model.save(f\"../misc/gan_model_{timestamp}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2872f12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !netron \"../misc/gan_model_{timestamp}.h5\" --port 8082"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354f4567",
   "metadata": {},
   "source": [
    "!!! If the shown model is the old pretrained model, you need to restart the kernal and run the notebook again!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d10a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = gan.train(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5408be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history['step'], history['d_loss_real'], label='Discriminator Loss Real')\n",
    "plt.plot(history['step'], history['d_loss_fake'], label='Discriminator Loss Fake')\n",
    "plt.plot(history['step'], history['g_adversarial'], label='Generator Adversarial')\n",
    "plt.plot(history['step'], history['g_l2'], label='Generator L2')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('GAN Training Losses')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9fa53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.g_model.save(f'../misc/generator_model_{timestamp}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570873dd",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#4FC3F7; border-bottom:2px solid #4FC3F7; padding-bottom:4px;\">\n",
    "4. Simulation\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0121d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SimulationData:\n",
    "    \"\"\"\n",
    "    Data class containing the simulation dynamical inputs, results and some minor settings.\n",
    "    \"\"\"\n",
    "    # Blood Glucose\n",
    "    gen_bg_scaled_arrays: np.ndarray\n",
    "\n",
    "    real_bg_scaled: np.ndarray\n",
    "    real_bg_unscaled: np.ndarray\n",
    "    gen_bg_unscaled: np.ndarray = None\n",
    "\n",
    "    PI_scaled: np.ndarray = None\n",
    "    RA_scaled: np.ndarray = None\n",
    "    PA_scaled: np.ndarray = None\n",
    "    IG_scaled: np.ndarray = None\n",
    "\n",
    "    # Plotting data\n",
    "    PI_unscaled: np.ndarray = None\n",
    "    RA_unscaled: np.ndarray = None\n",
    "    PA_unscaled: np.ndarray = None\n",
    "    IG_unscaled: np.ndarray = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ad2fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patient_sim_data(data_dict, simulation_length_in_days: int) -> SimulationData:\n",
    "    real_bg_unscaled = data_dict['BG']  # take the original vector to compare against the generated profile\n",
    "    real_bg_scaled = data_dict['scBG_packed']  # this is packed\n",
    "    gan_inputs = ['BG', 'scBG_packed', 'PI', 'RA']\n",
    "\n",
    "    # Calculate the number of days to simulate\n",
    "    days_to_simulate = min(len(real_bg_unscaled) / 288, simulation_length_in_days)\n",
    "    time_steps = int(288 * days_to_simulate)\n",
    "\n",
    "    sim_data_dict = {\n",
    "        'real_bg_unscaled': real_bg_unscaled.ravel()[:time_steps],\n",
    "        'real_bg_scaled': real_bg_scaled[:, 0, 0][:time_steps],\n",
    "    }\n",
    "\n",
    "    for input_name in gan_inputs:\n",
    "        if input_name != 'BG' and input_name != 'scBG_packed':\n",
    "            sim_data_dict[f'{input_name}_scaled'] = data_dict[f'sc{input_name}'][:time_steps]\n",
    "            sim_data_dict[f'{input_name}_unscaled'] = data_dict[input_name][:time_steps]\n",
    "\n",
    "    sim_data_dict['gen_bg_scaled_arrays'] = np.zeros(\n",
    "        (\n",
    "            1,\n",
    "            time_steps,\n",
    "            time_steps + 18,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    sim_data = SimulationData(**sim_data_dict)\n",
    "    return sim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ae396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load from misc the .h5\n",
    "generator = tf.keras.models.load_model(f'../misc/generator_model_{timestamp}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d51100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sim_data = load_patient_sim_data(data_dict, simulation_length_in_days=settings.simulation_length_in_days)\n",
    "simulator_instance = SimulatorVAEGAN(settings)\n",
    "simulated_data = simulator_instance.simulate(input_sim_data, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b35e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = len(simulated_data.gen_bg_unscaled)\n",
    "x_hours = np.arange(num_points) * 5 / 60  # 5 min per sample, convert to hours\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# First subplot: Blood glucose comparison\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(x_hours, simulated_data.gen_bg_unscaled, label='Simulated BG', color='blue')\n",
    "plt.plot(x_hours, simulated_data.real_bg_unscaled, label='Real BG', color='red')\n",
    "plt.xlabel('Time (hours)')\n",
    "plt.ylabel('Plasma Glucose Concentration (mg/dL)')\n",
    "plt.title('Blood Glucose Comparison')\n",
    "plt.xticks(\n",
    "    ticks=np.arange(0, x_hours[-1]+1, 2),\n",
    "    labels=[f\"{int(t)}\" for t in np.arange(0, x_hours[-1]+1, 2)]\n",
    ")\n",
    "plt.xlim([0, x_hours[-1]])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Second subplot: Plasma Insulin (PI)\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(x_hours, simulated_data.PI_unscaled.flatten()*-1, label='Plasma Insulin (PI)', color='green')\n",
    "plt.xlabel('Time (hours)')\n",
    "plt.ylabel('Plasma Insulin (U/L)')\n",
    "plt.title('Plasma Insulin Input')\n",
    "plt.xticks(\n",
    "    ticks=np.arange(0, x_hours[-1]+1, 2),\n",
    "    labels=[f\"{int(t)}\" for t in np.arange(0, x_hours[-1]+1, 2)]\n",
    ")\n",
    "plt.xlim([0, x_hours[-1]])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Third subplot: Rate of Appearance (RA)\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(x_hours, simulated_data.RA_unscaled.flatten(), label='Rate of Appearance (RA)', color='orange')\n",
    "plt.xlabel('Time (hours)')\n",
    "plt.ylabel('Rate of Appearance (mg/kg/min)')\n",
    "plt.title('Rate of Appearance Input')\n",
    "plt.xticks(\n",
    "    ticks=np.arange(0, x_hours[-1]+1, 2),\n",
    "    labels=[f\"{int(t)}\" for t in np.arange(0, x_hours[-1]+1, 2)]\n",
    ")\n",
    "plt.xlim([0, x_hours[-1]])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1093bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(bg_data, label):\n",
    "    \"\"\"Calculate metrics for a single BG array\"\"\"\n",
    "    mean_bg = np.mean(bg_data)\n",
    "    std_bg = np.std(bg_data)\n",
    "    cv = (std_bg / mean_bg) * 100\n",
    "    min_bg = np.min(bg_data)\n",
    "    max_bg = np.max(bg_data)\n",
    "\n",
    "    time_below_range = (np.sum(bg_data < 70) / len(bg_data)) * 100  # TBR\n",
    "    time_in_range = (np.sum((bg_data >= 70) & (bg_data <= 180)) / len(bg_data)) * 100  # TIR\n",
    "    time_above_range = (np.sum(bg_data > 180) / len(bg_data)) * 100  # TAR\n",
    "    time_in_tight_range = (np.sum((bg_data >= 70) & (bg_data <= 140)) / len(bg_data)) * 100  # TITR\n",
    "\n",
    "    return {\n",
    "        f'Mean BG (mg/dL) - {label}': mean_bg,\n",
    "        f'Std BG (mg/dL) - {label}': std_bg,\n",
    "        f'CV (%) - {label}': cv,\n",
    "        f'Min BG (mg/dL) - {label}': min_bg,\n",
    "        f'Max BG (mg/dL) - {label}': max_bg,\n",
    "        f'TBR (<70 mg/dL, %) - {label}': time_below_range,\n",
    "        f'TIR (70-180 mg/dL, %) - {label}': time_in_range,\n",
    "        f'TAR (>180 mg/dL, %) - {label}': time_above_range,\n",
    "        f'TITR (70-140 mg/dL, %) - {label}': time_in_tight_range\n",
    "    }\n",
    "\n",
    "def compute_glycemic_metrics(simulated_data: SimulationData) -> pd.DataFrame:\n",
    "    real_bg = simulated_data.real_bg_unscaled\n",
    "    sim_bg = simulated_data.gen_bg_unscaled\n",
    "\n",
    "    min_length = min(len(real_bg), len(sim_bg))\n",
    "    real_bg = real_bg[:min_length]\n",
    "    sim_bg = sim_bg[:min_length]\n",
    "\n",
    "    real_metrics = calculate_metrics(real_bg, 'Real')\n",
    "    sim_metrics = calculate_metrics(sim_bg, 'Simulated')\n",
    "\n",
    "    all_metrics = {**real_metrics, **sim_metrics}\n",
    "\n",
    "    metrics_data = {\n",
    "        'Metric': [],\n",
    "        'Real': [],\n",
    "        'Simulated': []\n",
    "    }\n",
    "\n",
    "    metric_names = [\n",
    "        'Mean BG (mg/dL)',\n",
    "        'Std BG (mg/dL)',\n",
    "        'CV (%)',\n",
    "        'Min BG (mg/dL)',\n",
    "        'Max BG (mg/dL)',\n",
    "        'TBR (<70 mg/dL, %)',\n",
    "        'TIR (70-180 mg/dL, %)',\n",
    "        'TAR (>180 mg/dL, %)',\n",
    "        'TITR (70-140 mg/dL, %)'\n",
    "    ]\n",
    "\n",
    "    for metric in metric_names:\n",
    "        metrics_data['Metric'].append(metric)\n",
    "        metrics_data['Real'].append(all_metrics[f'{metric} - Real'])\n",
    "        metrics_data['Simulated'].append(all_metrics[f'{metric} - Simulated'])\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_data)\n",
    "\n",
    "    metrics_df['Real'] = metrics_df['Real'].round(2)\n",
    "    metrics_df['Simulated'] = metrics_df['Simulated'].round(2)\n",
    "\n",
    "    return metrics_df\n",
    "\n",
    "glycemic_metrics_table = compute_glycemic_metrics(simulated_data)\n",
    "display(glycemic_metrics_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586d9503",
   "metadata": {},
   "source": [
    "<h2 style=\"color:#4FC3F7; border-bottom:2px solid #4FC3F7; padding-bottom:4px;\">\n",
    "5. Exercises\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd35d10f",
   "metadata": {},
   "source": [
    "The following are open exploration, slightly more advanced exercises. There is no correct answer for each question, and they are ordered by difficulty.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2d75ce",
   "metadata": {},
   "source": [
    "#### 1. Hyperparameter Exploration\n",
    "\n",
    "**Exercise**: Change hyperparameters (learning rate, prediction horizon, batch size, epochs etc.).\n",
    "\n",
    "- Train again and compare how convergence and results change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f6c151",
   "metadata": {},
   "source": [
    "#### 2. Interpretation & Validation\n",
    "\n",
    "**Exercise**: Look at the generated patient data and the real data, are they \"similar\"?\n",
    "\n",
    "- How can we validate if the generated patient data comes from the same distribution as the original subject? \n",
    "  - Take into account the model is stochastic by nature in order to represent the inerent intra-patient variability found in real life. This means error metrics like RMSE don't apply to this context, as every new generation might be different.\n",
    "  - If every new generated BG profile is the same, for the same inputs, your GAN has possibly experienced mode collapse.\n",
    "- Suggest at least one alternative validation strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825e150b",
   "metadata": {},
   "source": [
    "#### 3. Causality\n",
    "\n",
    "**Exercise**: Is your model causal?\n",
    "\n",
    "- Apply Convergent Cross Mapping (CCM) / Granger causality tests between insulin/carbs and glucose.\n",
    "- Modify inputs (meals, insulin boluses).\n",
    "  - Reuse Part A's preprocessing to transform discrete inputs you create into the continuus PI/RA vectors the model interprets.\n",
    "- Discuss whether the model reflects physiological cause–effect relationships or just correlations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
